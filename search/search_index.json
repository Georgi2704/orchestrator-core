{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Orchestrator-Core Production ready Orchestration Framework to manage product lifecyle and workflows. Easy to use, Built on top of FastAPI The orchestrator core is a project developed by SURF to facilitate the orchestration of services. Together with ESnet this project has been opensourced in the commons conservancy to help facilitate collaboration. We invite all who are interested to take a look and to contribute! Orchestration When do you orchestrate and when do you automate. The answer is you probably need both. Automation helps you execute repetetive tasks reliably and easily, Orchestration adds a layer and allows you to add more intelligence to the tasks you need to automate. Orchestrate * - Transitive Verb /\u02c8\u00f4rk\u0259\u02ccstr\u0101t/ /\u02c8\u0254rk\u0259\u02ccstre\u026at/ 1: Arrange or score (music) for orchestral performance. \u2018the song cycle was stunningly arranged and orchestrated\u2019 2: Arrange or direct the elements of (a situation) to produce a desired effect, especially surreptitiously. \u2018the developers were able to orchestrate a favorable media campaign\u2019 Project Goal This orchestrator-core provides a framework through which you can manage service orchestration for your end users. It enables you to define products to which users can subscribe, and helps you intelligently manage the lifecycle of Creation , Modification , Termination and Validation of a customer subscription. Usage This project can be installed as follows: Step 1: Install the core. pip install orchestrator-core Step 2: Create a postgres database: createuser -sP nwa createdb orchestrator-core -O nwa Step 3 (optional): When using multiple workers, you will need a redis server for live updates with websockets. By default it will use memory which works with only one worker. export WEBSOCKET_BROADCASTER_URL = \"memory://\" For the redis connection you need to set the env variable with the connection url. export WEBSOCKET_BROADCASTER_URL = \"redis://localhost:6379\" Websockets can also be turned off with: export ENABLE_WEBSOCKETS = False more broadcaster info here Step 4: Create a main.py file. from orchestrator import OrchestratorCore from orchestrator.cli.main import app as core_cli from orchestrator.settings import AppSettings app = OrchestratorCore ( base_settings = AppSettings ()) if __name__ == \"__main__\" : core_cli () Step 5: Initialize the migration environment. PYTHONPATH = . python main.py db init PYTHONPATH = . python main.py db upgrade heads Step 6: Profit :) uvicorn --reload --host 127 .0.0.1 --port 8080 main:app Visit http://127.0.0.1:8080/api/redoc to view the api documentation. Setting up a development environment To add features to the repository follow the following procedure to setup a working development environment. Installation (Development standalone) Install the project and its dependencies to develop on the code. Step 1 - install flit: python3 -m venv venv source venv/bin/activate pip install flit Step 2 - install the development code: flit install --deps develop --symlink --python venv/bin/python pip install redis Danger Make sure to use the flit binary that is installed in your environment. You can check the correct path by running which flit To be sure that the packages will be installed against the correct venv you can also prepend the python interpreter that you want to use: flit install --deps develop --symlink --python venv/bin/python pip install redis Running tests Run the unit-test suite to verify a correct setup. Step 1 - Create a database createuser -sP nwa createdb orchestrator-core-test -O nwa Step 2 - Run tests pytest test/unit_tests or with xdist: pytest -n auto test/unit_tests If you do not encounter any failures in the test, you should be able to develop features in the orchestrator-core. Installation (Development symlinked into orchestrator SURF) If you are working on a project that already uses the orchestrator-core and you want to test your new core features against it, you can use some flit magic to symlink the dev version of the core to your project. It will automatically replace the pypi dep with a symlink to the development version of the core and update/downgrade all required packages in your own orchestrator project. Step 1 - install flit: python - m venv venv source venv/bin/activate pip install flit Step 2 - symlink the core to your own project flit install --deps develop --symlink --python /path/to/a/orchestrator-project/venv/bin/python So if you have the core and your own orchestrator project repo in the same folder and the main project folder is orchestrator and you want to use relative links, this will be last step: flit install --deps develop --symlink --python ../orchestrator/venv/bin/python","title":"Orchestrator Core"},{"location":"#orchestrator-core","text":"Production ready Orchestration Framework to manage product lifecyle and workflows. Easy to use, Built on top of FastAPI The orchestrator core is a project developed by SURF to facilitate the orchestration of services. Together with ESnet this project has been opensourced in the commons conservancy to help facilitate collaboration. We invite all who are interested to take a look and to contribute!","title":"Orchestrator-Core"},{"location":"#orchestration","text":"When do you orchestrate and when do you automate. The answer is you probably need both. Automation helps you execute repetetive tasks reliably and easily, Orchestration adds a layer and allows you to add more intelligence to the tasks you need to automate.","title":"Orchestration"},{"location":"#orchestrate-transitive-verb","text":"/\u02c8\u00f4rk\u0259\u02ccstr\u0101t/ /\u02c8\u0254rk\u0259\u02ccstre\u026at/ 1: Arrange or score (music) for orchestral performance. \u2018the song cycle was stunningly arranged and orchestrated\u2019 2: Arrange or direct the elements of (a situation) to produce a desired effect, especially surreptitiously. \u2018the developers were able to orchestrate a favorable media campaign\u2019","title":"Orchestrate* - Transitive Verb"},{"location":"#project-goal","text":"This orchestrator-core provides a framework through which you can manage service orchestration for your end users. It enables you to define products to which users can subscribe, and helps you intelligently manage the lifecycle of Creation , Modification , Termination and Validation of a customer subscription.","title":"Project Goal"},{"location":"#usage","text":"This project can be installed as follows:","title":"Usage"},{"location":"#step-1","text":"Install the core. pip install orchestrator-core","title":"Step 1:"},{"location":"#step-2","text":"Create a postgres database: createuser -sP nwa createdb orchestrator-core -O nwa","title":"Step 2:"},{"location":"#step-3-optional","text":"When using multiple workers, you will need a redis server for live updates with websockets. By default it will use memory which works with only one worker. export WEBSOCKET_BROADCASTER_URL = \"memory://\" For the redis connection you need to set the env variable with the connection url. export WEBSOCKET_BROADCASTER_URL = \"redis://localhost:6379\" Websockets can also be turned off with: export ENABLE_WEBSOCKETS = False more broadcaster info here","title":"Step 3 (optional):"},{"location":"#step-4","text":"Create a main.py file. from orchestrator import OrchestratorCore from orchestrator.cli.main import app as core_cli from orchestrator.settings import AppSettings app = OrchestratorCore ( base_settings = AppSettings ()) if __name__ == \"__main__\" : core_cli ()","title":"Step 4:"},{"location":"#step-5","text":"Initialize the migration environment. PYTHONPATH = . python main.py db init PYTHONPATH = . python main.py db upgrade heads","title":"Step 5:"},{"location":"#step-6","text":"Profit :) uvicorn --reload --host 127 .0.0.1 --port 8080 main:app Visit http://127.0.0.1:8080/api/redoc to view the api documentation.","title":"Step 6:"},{"location":"#setting-up-a-development-environment","text":"To add features to the repository follow the following procedure to setup a working development environment.","title":"Setting up a development environment"},{"location":"#installation-development-standalone","text":"Install the project and its dependencies to develop on the code.","title":"Installation (Development standalone)"},{"location":"#step-1-install-flit","text":"python3 -m venv venv source venv/bin/activate pip install flit","title":"Step 1 - install flit:"},{"location":"#step-2-install-the-development-code","text":"flit install --deps develop --symlink --python venv/bin/python pip install redis Danger Make sure to use the flit binary that is installed in your environment. You can check the correct path by running which flit To be sure that the packages will be installed against the correct venv you can also prepend the python interpreter that you want to use: flit install --deps develop --symlink --python venv/bin/python pip install redis","title":"Step 2 - install the development code:"},{"location":"#running-tests","text":"Run the unit-test suite to verify a correct setup.","title":"Running tests"},{"location":"#step-1-create-a-database","text":"createuser -sP nwa createdb orchestrator-core-test -O nwa","title":"Step 1 - Create a database"},{"location":"#step-2-run-tests","text":"pytest test/unit_tests or with xdist: pytest -n auto test/unit_tests If you do not encounter any failures in the test, you should be able to develop features in the orchestrator-core.","title":"Step 2 - Run tests"},{"location":"#installation-development-symlinked-into-orchestrator-surf","text":"If you are working on a project that already uses the orchestrator-core and you want to test your new core features against it, you can use some flit magic to symlink the dev version of the core to your project. It will automatically replace the pypi dep with a symlink to the development version of the core and update/downgrade all required packages in your own orchestrator project.","title":"Installation (Development symlinked into orchestrator SURF)"},{"location":"#step-1-install-flit_1","text":"python - m venv venv source venv/bin/activate pip install flit","title":"Step 1 - install flit:"},{"location":"#step-2-symlink-the-core-to-your-own-project","text":"flit install --deps develop --symlink --python /path/to/a/orchestrator-project/venv/bin/python So if you have the core and your own orchestrator project repo in the same folder and the main project folder is orchestrator and you want to use relative links, this will be last step: flit install --deps develop --symlink --python ../orchestrator/venv/bin/python","title":"Step 2 - symlink the core to your own project"},{"location":"architecture/tldr/","text":"Architecture; TLDR The architecture of how the orchestrator-core is setup can be split in two sections. The orchestration philosophy of how workflows are setup and run, and how the application can be used to define products that can be subscribed to by customers. Application architecture If you follow the examples in the examples directory and Getting started you should be up and running in a short while. The Application extends a FastAPI application and therefore can make use of all the awesome features of FastAPI, pydantic and asyncio python. Step Engine At its core the Orchestrator workflow engine will execute a list of functions in order and store the result of each function to the database. The Orchestrator is able to execute any list of functions that the user envisions so long as they return a dictionary and/or consume variables stored in keys under that dictionary. @workflow ( \"Name of the workflow\" , initial_input_form = input_form_generator ) def workflow (): return ( init >> arbitrary_step_func_1 >> arbitrary_step_func_2 >> arbitrary_step_func_3 >> done ) The @workflow decorator converts what the function returns into a StepList which the engine executes sequentially. If and when the step functions raise an exeption, the workflow will fail at that step and allow the user to retry. Products and Subscriptions The second part of the orchestrator is a product database that allows a developer to define a collection of logically grouped resources, that when filled in create a Subscription, given to a customer. The description of a product is done in the Product , FixedInput , ProductBlock and ResourceType tables. When a workflow creates a subscription for a customer it creates instances of a Product , ProductBlock and ResourceType and stores them as Subscriptions , SubscriptionInstances and `SubscriptionInstanceValues. It is therefore possible to have N number of Subscriptions to a single product. A workflow is typically executed to manipulate a Subscription and transition it from one lifecycle state to another ( Initial , Provisioning , Active , Terminated ).","title":"Architecture; TLDR"},{"location":"architecture/tldr/#architecture-tldr","text":"The architecture of how the orchestrator-core is setup can be split in two sections. The orchestration philosophy of how workflows are setup and run, and how the application can be used to define products that can be subscribed to by customers.","title":"Architecture; TLDR"},{"location":"architecture/tldr/#application-architecture","text":"If you follow the examples in the examples directory and Getting started you should be up and running in a short while. The Application extends a FastAPI application and therefore can make use of all the awesome features of FastAPI, pydantic and asyncio python.","title":"Application architecture"},{"location":"architecture/tldr/#step-engine","text":"At its core the Orchestrator workflow engine will execute a list of functions in order and store the result of each function to the database. The Orchestrator is able to execute any list of functions that the user envisions so long as they return a dictionary and/or consume variables stored in keys under that dictionary. @workflow ( \"Name of the workflow\" , initial_input_form = input_form_generator ) def workflow (): return ( init >> arbitrary_step_func_1 >> arbitrary_step_func_2 >> arbitrary_step_func_3 >> done ) The @workflow decorator converts what the function returns into a StepList which the engine executes sequentially. If and when the step functions raise an exeption, the workflow will fail at that step and allow the user to retry.","title":"Step Engine"},{"location":"architecture/tldr/#products-and-subscriptions","text":"The second part of the orchestrator is a product database that allows a developer to define a collection of logically grouped resources, that when filled in create a Subscription, given to a customer. The description of a product is done in the Product , FixedInput , ProductBlock and ResourceType tables. When a workflow creates a subscription for a customer it creates instances of a Product , ProductBlock and ResourceType and stores them as Subscriptions , SubscriptionInstances and `SubscriptionInstanceValues. It is therefore possible to have N number of Subscriptions to a single product. A workflow is typically executed to manipulate a Subscription and transition it from one lifecycle state to another ( Initial , Provisioning , Active , Terminated ).","title":"Products and Subscriptions"},{"location":"architecture/application/api/","text":"Api documentation const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', })","title":"Api Docs"},{"location":"architecture/application/api/#api-documentation","text":"const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', })","title":"Api documentation"},{"location":"architecture/application/domainmodels/","text":"Domain Models - Why do we need them? Domain Models are designed to help the developer manage complex subscription models and interact with the objects in a user-friendly way. Domain models leverage the Pydantic with some extra sauce to dynamically cast variables from the database where they are stored as a string to their correct type in Python at runtime. Domain Model benefits Strict MyPy typing and validation in models. Type Safe serialisation to and from the database Subscription lifecycle transition enforcement Hierarchy enforcement with domain models Customer Facing resources vs resource facing resources When implementing domain models it is possible to link all resources together as they are nodes in a graph through the relations defined in the domain models. Type Safety during serialisation Logic errors that depend on type evaluations/comparisons are prevented by using domain models to serialise database objects. This has a number of benefits as it saves the user the effort of casting the database result to the correct type and allows the developer to be more Type safe whilst developing. Example Example The main reason for developing domain models was to make sure bugs like this occured less. Pre domain models >>> some_subscription_instance_value = SubscriptionInstanceValueTable . get ( \"ID\" ) >>> instance_value_from_db = some_subscription_instance_value . value >>> instance_value_from_db \"False\" >>> if instance_value_from_db is True : ... print ( \"True\" ) ... else : ... print ( \"False\" ) \"True\" Post domain models >>> some_subscription_instance_value = SubscriptionInstanceValueTable . get ( \"ID\" ) >>> instance_value_from_db = some_subscription_instance_value . value >>> type ( instance_value_from_db ) < class str > >>> >>> subscription_model = SubscriptionModel . from_subscription ( \"ID\" ) >>> type ( subscription_model . product_block . instance_from_db ) < class bool > >>> >>> subscription_model . product_block . instance_from_db False >>> >>> if subscription_model . product_block . instance_from_db is True : ... print ( \"True\" ) ... else : ... print ( \"False\" ) \"False\" Lifecycle transitions When transitioning from Initial -> Provisioning -> Active -> Terminated in the Subscription Lifecycle the domain model definitions make sure that all resource types and product blocks are assigned correctly. Typically the Initial status is less strict compared to the Active lifecycle. When assigning product blocks from other subscriptions as children to a product blocks from the a subscription that is being modified, the domain-models respect Subscription boundaries and do not update variables and resources in the child Subscription product block. Enforcing Hierarchy When defining and modelling products it often is necessary to model resources that are parents or children of other product blocks. It may even be the case that a subscription product block needs a child product block from another subscription. Example In networking when creating a layer 2 circuit, one needs at least two interfaces and VLAN configuration to create the circuit. The interfaces may be owned by different customers than the owner of the circuit. Typically we assign a subscription to a customer which contains the interface resource. That interface resource is then used again in the circuit subscription, as a resource. Code examples Product Block Model Product block models are reusable Pydantic classes that enable the user to reuse product blocks in multiple Products. They are defined in lifecycle state and can be setup to be very restrictive or less restrictive. The orchestrator supports hierarchy in the way product block models reference each other. In other words, a product block model, may have a property that references one or more other product block models. Info The Product block model should be modeled as though it is a resource that can be re-used in multiple products. In networking the analogy would be: A physical interface may be used in a Layer 2 service and Layer 3 service It is not necessary to define two different physical interface types. Product Block Model - Inactive class ServicePortBlockInactive ( ProductBlockModel , product_block_name = \"Service Port\" ): \"\"\"Object model for a SN8 Service Port product block.\"\"\" node_subscription_id : Optional [ UUID ] = None nso_service_id : Optional [ UUID ] = None port_mode : Optional [ PortMode ] = None lldp : Optional [ bool ] = None ims_circuit_id : Optional [ int ] = None auto_negotiation : Optional [ bool ] = None As you can see in this model we define it as an Inactive Class. As parameter we pass the name of the product_block in the database. In the second highlighted line you see a variable. This references a resource_type in the database, and annotates what type it should be at runtime. In the Inactive or Initial phase of the Subscripton lifecycle we are least restrictive in annotating the properties; All fields/resource types are Optional. Product Block Model - Provisioning class ServicePortBlockProvisioning ( ServicePortBlockInactive , lifecycle = [ SubscriptionLifecycle . PROVISIONING ] ): \"\"\"Object model for a SN8 Service Port product block in active state.\"\"\" node_subscription_id : UUID nso_service_id : UUID port_mode : PortMode lldp : bool ims_circuit_id : Optional [ int ] = None auto_negotiation : Optional [ bool ] = None In this stage whe have changed the way a Subscription domain model should look like in a certain Lifecyle state. You also see that the resource_type now no-longer is Optional. It must exist in this instantiation of the class. The model will raise a ValidationError upon .save() if typing is not filled in correctly. Product Block Model - Active class ServicePortBlock ( ServicePortBlockProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): \"\"\"Object model for a SN8 Service Port product block in active state.\"\"\" node_subscription_id : UUID nso_service_id : UUID port_mode : PortMode lldp : bool ims_circuit_id : int auto_negotiation : Optional [ bool ] = None The Class is now defined in it's most strict form, in other words in the Active lifecycle of a subscription, this product block model must have all resource_types filled in except for auto_negotiation to function correctly. Tip The stricter you are in defining your product block models the more you are able to leverage the built in validation of Pydantic . Product Model a.k.a SubscriptionModel Product models are very similar to Prodblock Models in that they adhere to the same principles as explained above. However the difference to Product Block models is that they create Subscriptions in the database. They must always have a reference to a customer and instead of containing other ProductBlockModel or resource_types they contain either fixed_inputs which basically describe fixed product attributes or other ProductBlockModels. Product Model - Inactive class ServicePortInitial ( SubscriptionModel , is_base = True , lifecycle = [ SubscriptionLifecycle . INITIAL , SubscriptionLifecycle . TERMINATED ] ): domain : Domain port_speed : PortSpeed port : Optional [ ServicePortBlockInactive ] = None In the above example you can observe the lifecyle definition as per the ProductBlockModels . Below that you see fixed_inputs These can be of any type, however if they are a SubClass of a ProductBlockModel the code will automatically create a database instance of that object. Product Model - Provisioning and Active class ServicePortProvisioning ( ServicePortInitial , lifecycle = [ SubscriptionLifecycle . PROVISIONING ] ): domain : Domain port_speed : PortSpeed port : ServicePortBlockProvisioning class ServicePort ( ServicePortProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): domain : Domain port_speed : PortSpeed port : ServicePortBlock Again you can observe how the Product definition changes depending on the lifecycle. It annotates a different type to the port property in SubscriptionLifecycle.ACTIVE compared to SubscriptionLifecycle.PROVISIONING . Advanced Use Cases Crossing the subscription boundary As mentioned before an advanced usecase would be to use ProductBlockModels from other Subscriptions. Example >>> first_service_port = ServicePort . from_subscription ( subscription_id = \"ID\" ) >>> first_service_port . customer_id \"Y\" >>> >>> second_service_port = ServicePort . from_product ( product_id = \"ID\" , customer_id = \"ID\" ) >>> second_service_port . port = first_service_port . port >>> second_service_port . save () >>> >>> second_service_port . port . subscription == first_service_port . subscription True >>> >>> second_service_port . port . subscription == second_service_port . subscription False This is valid use of the domain models. The code will detect that port is part of first_service_port and respect onwership. It basically will treat it as a read-only property. Union types There may also be a case where a user would like to define two different types to a ProductBlockModel propery. This can be achieved by using the Union type decorator. Danger When using this method be sure as to declare the Most specific type first. This is how Pydantic attempts to cast types to the property. For more background as to why, read here class ServicePort ( ServicePortProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): domain : Domain port_speed : PortSpeed port : Union [ ServicePortBlock , DifferentServicePortBlock ]","title":"Domain Models"},{"location":"architecture/application/domainmodels/#domain-models-why-do-we-need-them","text":"Domain Models are designed to help the developer manage complex subscription models and interact with the objects in a user-friendly way. Domain models leverage the Pydantic with some extra sauce to dynamically cast variables from the database where they are stored as a string to their correct type in Python at runtime. Domain Model benefits Strict MyPy typing and validation in models. Type Safe serialisation to and from the database Subscription lifecycle transition enforcement Hierarchy enforcement with domain models Customer Facing resources vs resource facing resources When implementing domain models it is possible to link all resources together as they are nodes in a graph through the relations defined in the domain models.","title":"Domain Models - Why do we need them?"},{"location":"architecture/application/domainmodels/#type-safety-during-serialisation","text":"Logic errors that depend on type evaluations/comparisons are prevented by using domain models to serialise database objects. This has a number of benefits as it saves the user the effort of casting the database result to the correct type and allows the developer to be more Type safe whilst developing.","title":"Type Safety during serialisation"},{"location":"architecture/application/domainmodels/#example","text":"Example The main reason for developing domain models was to make sure bugs like this occured less.","title":"Example"},{"location":"architecture/application/domainmodels/#pre-domain-models","text":">>> some_subscription_instance_value = SubscriptionInstanceValueTable . get ( \"ID\" ) >>> instance_value_from_db = some_subscription_instance_value . value >>> instance_value_from_db \"False\" >>> if instance_value_from_db is True : ... print ( \"True\" ) ... else : ... print ( \"False\" ) \"True\"","title":"Pre domain models"},{"location":"architecture/application/domainmodels/#post-domain-models","text":">>> some_subscription_instance_value = SubscriptionInstanceValueTable . get ( \"ID\" ) >>> instance_value_from_db = some_subscription_instance_value . value >>> type ( instance_value_from_db ) < class str > >>> >>> subscription_model = SubscriptionModel . from_subscription ( \"ID\" ) >>> type ( subscription_model . product_block . instance_from_db ) < class bool > >>> >>> subscription_model . product_block . instance_from_db False >>> >>> if subscription_model . product_block . instance_from_db is True : ... print ( \"True\" ) ... else : ... print ( \"False\" ) \"False\"","title":"Post domain models"},{"location":"architecture/application/domainmodels/#lifecycle-transitions","text":"When transitioning from Initial -> Provisioning -> Active -> Terminated in the Subscription Lifecycle the domain model definitions make sure that all resource types and product blocks are assigned correctly. Typically the Initial status is less strict compared to the Active lifecycle. When assigning product blocks from other subscriptions as children to a product blocks from the a subscription that is being modified, the domain-models respect Subscription boundaries and do not update variables and resources in the child Subscription product block.","title":"Lifecycle transitions"},{"location":"architecture/application/domainmodels/#enforcing-hierarchy","text":"When defining and modelling products it often is necessary to model resources that are parents or children of other product blocks. It may even be the case that a subscription product block needs a child product block from another subscription. Example In networking when creating a layer 2 circuit, one needs at least two interfaces and VLAN configuration to create the circuit. The interfaces may be owned by different customers than the owner of the circuit. Typically we assign a subscription to a customer which contains the interface resource. That interface resource is then used again in the circuit subscription, as a resource.","title":"Enforcing Hierarchy"},{"location":"architecture/application/domainmodels/#code-examples","text":"","title":"Code examples"},{"location":"architecture/application/domainmodels/#product-block-model","text":"Product block models are reusable Pydantic classes that enable the user to reuse product blocks in multiple Products. They are defined in lifecycle state and can be setup to be very restrictive or less restrictive. The orchestrator supports hierarchy in the way product block models reference each other. In other words, a product block model, may have a property that references one or more other product block models. Info The Product block model should be modeled as though it is a resource that can be re-used in multiple products. In networking the analogy would be: A physical interface may be used in a Layer 2 service and Layer 3 service It is not necessary to define two different physical interface types.","title":"Product Block Model"},{"location":"architecture/application/domainmodels/#product-block-model-inactive","text":"class ServicePortBlockInactive ( ProductBlockModel , product_block_name = \"Service Port\" ): \"\"\"Object model for a SN8 Service Port product block.\"\"\" node_subscription_id : Optional [ UUID ] = None nso_service_id : Optional [ UUID ] = None port_mode : Optional [ PortMode ] = None lldp : Optional [ bool ] = None ims_circuit_id : Optional [ int ] = None auto_negotiation : Optional [ bool ] = None As you can see in this model we define it as an Inactive Class. As parameter we pass the name of the product_block in the database. In the second highlighted line you see a variable. This references a resource_type in the database, and annotates what type it should be at runtime. In the Inactive or Initial phase of the Subscripton lifecycle we are least restrictive in annotating the properties; All fields/resource types are Optional.","title":"Product Block Model - Inactive"},{"location":"architecture/application/domainmodels/#product-block-model-provisioning","text":"class ServicePortBlockProvisioning ( ServicePortBlockInactive , lifecycle = [ SubscriptionLifecycle . PROVISIONING ] ): \"\"\"Object model for a SN8 Service Port product block in active state.\"\"\" node_subscription_id : UUID nso_service_id : UUID port_mode : PortMode lldp : bool ims_circuit_id : Optional [ int ] = None auto_negotiation : Optional [ bool ] = None In this stage whe have changed the way a Subscription domain model should look like in a certain Lifecyle state. You also see that the resource_type now no-longer is Optional. It must exist in this instantiation of the class. The model will raise a ValidationError upon .save() if typing is not filled in correctly.","title":"Product Block Model - Provisioning"},{"location":"architecture/application/domainmodels/#product-block-model-active","text":"class ServicePortBlock ( ServicePortBlockProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): \"\"\"Object model for a SN8 Service Port product block in active state.\"\"\" node_subscription_id : UUID nso_service_id : UUID port_mode : PortMode lldp : bool ims_circuit_id : int auto_negotiation : Optional [ bool ] = None The Class is now defined in it's most strict form, in other words in the Active lifecycle of a subscription, this product block model must have all resource_types filled in except for auto_negotiation to function correctly. Tip The stricter you are in defining your product block models the more you are able to leverage the built in validation of Pydantic .","title":"Product Block Model - Active"},{"location":"architecture/application/domainmodels/#product-model-aka-subscriptionmodel","text":"Product models are very similar to Prodblock Models in that they adhere to the same principles as explained above. However the difference to Product Block models is that they create Subscriptions in the database. They must always have a reference to a customer and instead of containing other ProductBlockModel or resource_types they contain either fixed_inputs which basically describe fixed product attributes or other ProductBlockModels.","title":"Product Model a.k.a SubscriptionModel"},{"location":"architecture/application/domainmodels/#product-model-inactive","text":"class ServicePortInitial ( SubscriptionModel , is_base = True , lifecycle = [ SubscriptionLifecycle . INITIAL , SubscriptionLifecycle . TERMINATED ] ): domain : Domain port_speed : PortSpeed port : Optional [ ServicePortBlockInactive ] = None In the above example you can observe the lifecyle definition as per the ProductBlockModels . Below that you see fixed_inputs These can be of any type, however if they are a SubClass of a ProductBlockModel the code will automatically create a database instance of that object.","title":"Product Model - Inactive"},{"location":"architecture/application/domainmodels/#product-model-provisioning-and-active","text":"class ServicePortProvisioning ( ServicePortInitial , lifecycle = [ SubscriptionLifecycle . PROVISIONING ] ): domain : Domain port_speed : PortSpeed port : ServicePortBlockProvisioning class ServicePort ( ServicePortProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): domain : Domain port_speed : PortSpeed port : ServicePortBlock Again you can observe how the Product definition changes depending on the lifecycle. It annotates a different type to the port property in SubscriptionLifecycle.ACTIVE compared to SubscriptionLifecycle.PROVISIONING .","title":"Product Model -  Provisioning and Active"},{"location":"architecture/application/domainmodels/#advanced-use-cases","text":"","title":"Advanced Use Cases"},{"location":"architecture/application/domainmodels/#crossing-the-subscription-boundary","text":"As mentioned before an advanced usecase would be to use ProductBlockModels from other Subscriptions. Example >>> first_service_port = ServicePort . from_subscription ( subscription_id = \"ID\" ) >>> first_service_port . customer_id \"Y\" >>> >>> second_service_port = ServicePort . from_product ( product_id = \"ID\" , customer_id = \"ID\" ) >>> second_service_port . port = first_service_port . port >>> second_service_port . save () >>> >>> second_service_port . port . subscription == first_service_port . subscription True >>> >>> second_service_port . port . subscription == second_service_port . subscription False This is valid use of the domain models. The code will detect that port is part of first_service_port and respect onwership. It basically will treat it as a read-only property.","title":"Crossing the subscription boundary"},{"location":"architecture/application/domainmodels/#union-types","text":"There may also be a case where a user would like to define two different types to a ProductBlockModel propery. This can be achieved by using the Union type decorator. Danger When using this method be sure as to declare the Most specific type first. This is how Pydantic attempts to cast types to the property. For more background as to why, read here class ServicePort ( ServicePortProvisioning , lifecycle = [ SubscriptionLifecycle . ACTIVE ]): domain : Domain port_speed : PortSpeed port : Union [ ServicePortBlock , DifferentServicePortBlock ]","title":"Union types"},{"location":"architecture/application/workflow/","text":"What is a workflow and how does it work? The workflow engine is the core of the software it has been created to execute a number of functions. Safely and reliable manipulate customer Subscriptions from one state to the next and maintain auditability. Create an API through which programatically Subscriptions can be manipulated. Execute step functions in order and allow the retry of previously failed process-steps in an idempotent way. Atomically execute workflow functions.","title":"How do Workflows work?"},{"location":"architecture/application/workflow/#what-is-a-workflow-and-how-does-it-work","text":"The workflow engine is the core of the software it has been created to execute a number of functions. Safely and reliable manipulate customer Subscriptions from one state to the next and maintain auditability. Create an API through which programatically Subscriptions can be manipulated. Execute step functions in order and allow the retry of previously failed process-steps in an idempotent way. Atomically execute workflow functions.","title":"What is a workflow and how does it work?"},{"location":"architecture/orchestration/philosophy/","text":"","title":"Orchestration Philosofy"},{"location":"contributing/guidelines/","text":"Contributing We welcome all contributions, whether questions, code or documentation. We will add sections about how to contribute in in the near future. Documentation We use MKDOCS as a documentation tool. Please create a PR if you have any additions or contributions to make. All docs can be written in MD or html.","title":"Guidelines"},{"location":"contributing/guidelines/#contributing","text":"We welcome all contributions, whether questions, code or documentation. We will add sections about how to contribute in in the near future.","title":"Contributing"},{"location":"contributing/guidelines/#documentation","text":"We use MKDOCS as a documentation tool. Please create a PR if you have any additions or contributions to make. All docs can be written in MD or html.","title":"Documentation"},{"location":"getting-started/base/","text":"Bare application By following these steps you can start a bare orchestrator-core application that can be used to run workflows. Note The Orchestrator-core is designed to be installed and extended just like a FastAPI or Flask application. For more information about how this works read the Architecture sections. Step 1 - Install the package: Install the core. $ pip install orchestrator-core ---> 100% Successfully installed orchestrator-core Step 2 - Setup the database: Create a postgres database: $ createuser -sP nwa $ createdb orchestrator-core -O nwa Step 3 - Create the main.py: Create a main.py file. from orchestrator import OrchestratorCore from orchestrator.cli.main import app as core_cli from orchestrator.settings import AppSettings app = OrchestratorCore ( base_settings = AppSettings ()) if __name__ == \"__main__\" : core_cli () Step 4 - Run the database migrations: Initialize the migration environment. $ PYTHONPATH = . python main.py db init $ PYTHONPATH = . python main.py db upgrade heads Step 5 - Run the app $ uvicorn --reload --host 127 .0.0.1 --port 8080 main:app INFO: Uvicorn running on http://127.0.0.1:8080 ( Press CTRL+C to quit ) INFO: Started reloader process [ 62967 ] using watchgod ujson module not found, using json msgpack not installed, MsgPackSerializer unavailable 2021 -09-28 09 :42:14 [ warning ] Database object configured, all methods referencing ` db ` should work. [ orchestrator.db ] INFO: Started server process [ 62971 ] 2021 -09-28 09 :42:14 [ info ] Started server process [ 62971 ] [ uvicorn.error ] INFO: Waiting for application startup. 2021 -09-28 09 :42:14 [ info ] Waiting for application startup. [ uvicorn.error ] INFO: Application startup complete. 2021 -09-28 09 :42:14 [ info ] Application startup complete. [ uvicorn.error ] Step 6 - Profit Visit the app to view the api documentation.","title":"Base Application"},{"location":"getting-started/base/#bare-application","text":"By following these steps you can start a bare orchestrator-core application that can be used to run workflows. Note The Orchestrator-core is designed to be installed and extended just like a FastAPI or Flask application. For more information about how this works read the Architecture sections.","title":"Bare application"},{"location":"getting-started/base/#step-1-install-the-package","text":"Install the core. $ pip install orchestrator-core ---> 100% Successfully installed orchestrator-core","title":"Step 1 - Install the package:"},{"location":"getting-started/base/#step-2-setup-the-database","text":"Create a postgres database: $ createuser -sP nwa $ createdb orchestrator-core -O nwa","title":"Step 2 - Setup the database:"},{"location":"getting-started/base/#step-3-create-the-mainpy","text":"Create a main.py file. from orchestrator import OrchestratorCore from orchestrator.cli.main import app as core_cli from orchestrator.settings import AppSettings app = OrchestratorCore ( base_settings = AppSettings ()) if __name__ == \"__main__\" : core_cli ()","title":"Step 3 - Create the main.py:"},{"location":"getting-started/base/#step-4-run-the-database-migrations","text":"Initialize the migration environment. $ PYTHONPATH = . python main.py db init $ PYTHONPATH = . python main.py db upgrade heads","title":"Step 4 - Run the database migrations:"},{"location":"getting-started/base/#step-5-run-the-app","text":"$ uvicorn --reload --host 127 .0.0.1 --port 8080 main:app INFO: Uvicorn running on http://127.0.0.1:8080 ( Press CTRL+C to quit ) INFO: Started reloader process [ 62967 ] using watchgod ujson module not found, using json msgpack not installed, MsgPackSerializer unavailable 2021 -09-28 09 :42:14 [ warning ] Database object configured, all methods referencing ` db ` should work. [ orchestrator.db ] INFO: Started server process [ 62971 ] 2021 -09-28 09 :42:14 [ info ] Started server process [ 62971 ] [ uvicorn.error ] INFO: Waiting for application startup. 2021 -09-28 09 :42:14 [ info ] Waiting for application startup. [ uvicorn.error ] INFO: Application startup complete. 2021 -09-28 09 :42:14 [ info ] Application startup complete. [ uvicorn.error ]","title":"Step 5 - Run the app"},{"location":"getting-started/base/#step-6-profit","text":"Visit the app to view the api documentation.","title":"Step 6 - Profit"},{"location":"getting-started/development/","text":"Setting up a development environment To add features to the repository follow the following procedure to setup a working development environment. Installation (Development) Install the project and its dependancies to develop on the code. Step 1 - install flit: pip install flit Step 2 - install the development code: flit install --deps develop --symlink Danger Make sure to use the flit binary that is installed in your environment. You can check the correct path by running which flit Running tests Run the unit-test suite to verify a correct setup. Step 1 - Create a database createuser -sP nwa createdb orchestrator-core-test -O nwa Step 2 - Run tests pytest test/unit_tests If you do not encounter any failures in the test, you should be able to develop features in the orchestrator-core.","title":"Development setup"},{"location":"getting-started/development/#setting-up-a-development-environment","text":"To add features to the repository follow the following procedure to setup a working development environment.","title":"Setting up a development environment"},{"location":"getting-started/development/#installation-development","text":"Install the project and its dependancies to develop on the code.","title":"Installation (Development)"},{"location":"getting-started/development/#step-1-install-flit","text":"pip install flit","title":"Step 1 - install flit:"},{"location":"getting-started/development/#step-2-install-the-development-code","text":"flit install --deps develop --symlink Danger Make sure to use the flit binary that is installed in your environment. You can check the correct path by running which flit","title":"Step 2 - install the development code:"},{"location":"getting-started/development/#running-tests","text":"Run the unit-test suite to verify a correct setup.","title":"Running tests"},{"location":"getting-started/development/#step-1-create-a-database","text":"createuser -sP nwa createdb orchestrator-core-test -O nwa","title":"Step 1 - Create a database"},{"location":"getting-started/development/#step-2-run-tests","text":"pytest test/unit_tests If you do not encounter any failures in the test, you should be able to develop features in the orchestrator-core.","title":"Step 2 - Run tests"},{"location":"getting-started/workshop/answers-step3/","text":"Step 3 - Answers First generate the revision file. $ PYTHONPATH = . python main.py db revision --message \"My descriptive revision description\" --head = data@head An example database migration. \"\"\"My descriptive revision description. Revision ID: 9bb25a23206b Revises: 41e637ff569e Create Date: 2020-12-10 21:38:39.899085 \"\"\" from typing import Any import sqlalchemy as sa from alembic import op # revision identifiers, used by Alembic. from migrations.helpers import create_missing_modify_note_workflows from orchestrator.targets import Target revision = \"9bb25a23206b\" down_revision = \"41e637ff569e\" branch_labels = None depends_on = None product_name = \"Username registration\" workflow_name = \"create_username_registration\" product_blocks : list [ dict [ str , Any ]] = [ { \"name\" : \"Username\" , \"description\" : \"Username Registration\" , \"tag\" : \"UNR\" , \"status\" : \"active\" , \"resource_types\" : [ ( \"username\" , \"Unique name the person\" ), ], } ] def upgrade () -> None : conn = op . get_bind () conn . execute ( sa . text ( \"INSERT INTO products (name, description, product_type, tag, status)\" \"VALUES (:name, :description, :product_type, :tag, :status) ON CONFLICT DO NOTHING\" ), { \"name\" : product_name , \"description\" : \"The Username product\" , \"product_type\" : \"UNPT\" , \"tag\" : \"UNR\" , \"status\" : \"active\" , }, ) result = conn . execute ( sa . text ( \"SELECT product_id FROM products WHERE name=:name\" ), name = product_name ) product_id = result . fetchone ()[ 0 ] for block in product_blocks : conn . execute ( sa . text ( \"INSERT INTO product_blocks (name, description, tag, status) VALUES (:name, :description, :tag, :status)\" \"ON CONFLICT DO NOTHING\" ), name = block [ \"name\" ], description = block [ \"description\" ], tag = block [ \"tag\" ], status = block [ \"status\" ], ) result = conn . execute ( sa . text ( \"SELECT product_block_id FROM product_blocks WHERE name = :name\" ), name = block [ \"name\" ], ) product_block_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO product_product_blocks (product_id, product_block_id) VALUES (:product_id, :product_block_id)\" \"ON CONFLICT DO NOTHING\" ), product_id = product_id , product_block_id = product_block_id , ) for resource_type , description in block [ \"resource_types\" ]: conn . execute ( sa . text ( \"INSERT INTO resource_types (resource_type, description) VALUES (:resource_type, :description)\" \"ON CONFLICT DO NOTHING\" ), resource_type = resource_type , description = description , ) result = conn . execute ( sa . text ( \"SELECT resource_type_id FROM resource_types where resource_type = :resource_type\" ), resource_type = resource_type , ) resource_type_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO product_block_resource_types (product_block_id, resource_type_id)\" \"VALUES (:product_block_id, :resource_type_id)\" ), product_block_id = product_block_id , resource_type_id = resource_type_id , ) conn . execute ( sa . text ( \"INSERT INTO workflows (name, target, description) VALUES (:name, :target, :description)\" \"ON CONFLICT DO NOTHING\" ), { \"name\" : workflow_name , \"target\" : Target . CREATE , \"description\" : \"Create User\" }, ) result = conn . execute ( sa . text ( \"SELECT workflow_id FROM workflows WHERE name = :name\" ), name = workflow_name , ) workflow_id = result . fetchone ()[ 0 ] result = conn . execute ( sa . text ( \"SELECT product_id FROM products WHERE name=:name\" ), name = product_name ) product_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO products_workflows (product_id, workflow_id) VALUES (:product_id, :workflow_id)\" \"ON CONFLICT DO NOTHING\" ), { \"product_id\" : product_id , \"workflow_id\" : workflow_id }, ) create_missing_modify_note_workflows ( conn ) def downgrade () -> None : conn = op . get_bind () conn . execute ( sa . text ( \"DELETE FROM products WHERE name = :name\" ), name = product_name )","title":"Step 3 - Answer"},{"location":"getting-started/workshop/answers-step3/#step-3-answers","text":"First generate the revision file. $ PYTHONPATH = . python main.py db revision --message \"My descriptive revision description\" --head = data@head An example database migration. \"\"\"My descriptive revision description. Revision ID: 9bb25a23206b Revises: 41e637ff569e Create Date: 2020-12-10 21:38:39.899085 \"\"\" from typing import Any import sqlalchemy as sa from alembic import op # revision identifiers, used by Alembic. from migrations.helpers import create_missing_modify_note_workflows from orchestrator.targets import Target revision = \"9bb25a23206b\" down_revision = \"41e637ff569e\" branch_labels = None depends_on = None product_name = \"Username registration\" workflow_name = \"create_username_registration\" product_blocks : list [ dict [ str , Any ]] = [ { \"name\" : \"Username\" , \"description\" : \"Username Registration\" , \"tag\" : \"UNR\" , \"status\" : \"active\" , \"resource_types\" : [ ( \"username\" , \"Unique name the person\" ), ], } ] def upgrade () -> None : conn = op . get_bind () conn . execute ( sa . text ( \"INSERT INTO products (name, description, product_type, tag, status)\" \"VALUES (:name, :description, :product_type, :tag, :status) ON CONFLICT DO NOTHING\" ), { \"name\" : product_name , \"description\" : \"The Username product\" , \"product_type\" : \"UNPT\" , \"tag\" : \"UNR\" , \"status\" : \"active\" , }, ) result = conn . execute ( sa . text ( \"SELECT product_id FROM products WHERE name=:name\" ), name = product_name ) product_id = result . fetchone ()[ 0 ] for block in product_blocks : conn . execute ( sa . text ( \"INSERT INTO product_blocks (name, description, tag, status) VALUES (:name, :description, :tag, :status)\" \"ON CONFLICT DO NOTHING\" ), name = block [ \"name\" ], description = block [ \"description\" ], tag = block [ \"tag\" ], status = block [ \"status\" ], ) result = conn . execute ( sa . text ( \"SELECT product_block_id FROM product_blocks WHERE name = :name\" ), name = block [ \"name\" ], ) product_block_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO product_product_blocks (product_id, product_block_id) VALUES (:product_id, :product_block_id)\" \"ON CONFLICT DO NOTHING\" ), product_id = product_id , product_block_id = product_block_id , ) for resource_type , description in block [ \"resource_types\" ]: conn . execute ( sa . text ( \"INSERT INTO resource_types (resource_type, description) VALUES (:resource_type, :description)\" \"ON CONFLICT DO NOTHING\" ), resource_type = resource_type , description = description , ) result = conn . execute ( sa . text ( \"SELECT resource_type_id FROM resource_types where resource_type = :resource_type\" ), resource_type = resource_type , ) resource_type_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO product_block_resource_types (product_block_id, resource_type_id)\" \"VALUES (:product_block_id, :resource_type_id)\" ), product_block_id = product_block_id , resource_type_id = resource_type_id , ) conn . execute ( sa . text ( \"INSERT INTO workflows (name, target, description) VALUES (:name, :target, :description)\" \"ON CONFLICT DO NOTHING\" ), { \"name\" : workflow_name , \"target\" : Target . CREATE , \"description\" : \"Create User\" }, ) result = conn . execute ( sa . text ( \"SELECT workflow_id FROM workflows WHERE name = :name\" ), name = workflow_name , ) workflow_id = result . fetchone ()[ 0 ] result = conn . execute ( sa . text ( \"SELECT product_id FROM products WHERE name=:name\" ), name = product_name ) product_id = result . fetchone ()[ 0 ] conn . execute ( sa . text ( \"INSERT INTO products_workflows (product_id, workflow_id) VALUES (:product_id, :workflow_id)\" \"ON CONFLICT DO NOTHING\" ), { \"product_id\" : product_id , \"workflow_id\" : workflow_id }, ) create_missing_modify_note_workflows ( conn ) def downgrade () -> None : conn = op . get_bind () conn . execute ( sa . text ( \"DELETE FROM products WHERE name = :name\" ), name = product_name )","title":"Step 3 - Answers"},{"location":"getting-started/workshop/goal/","text":"Workshop goal The goal of this workshop is to guide the user through the first steps of creating their first workflow. After completing this workshop the user should understand the basic steps of creating a product and the workflows to manipulate that product. Workshop overview Install the package and setup the database Setup and run the orchestrator-core and orchestrator-core-gui projects together. Create your first product and domain model. Create your first workflow and input form Note This workshop will guide the user through the basic principles of the orchestrator. For in depth questions please contact the maintainers","title":"Goal of the workshop"},{"location":"getting-started/workshop/goal/#workshop-goal","text":"The goal of this workshop is to guide the user through the first steps of creating their first workflow. After completing this workshop the user should understand the basic steps of creating a product and the workflows to manipulate that product.","title":"Workshop goal"},{"location":"getting-started/workshop/goal/#workshop-overview","text":"Install the package and setup the database Setup and run the orchestrator-core and orchestrator-core-gui projects together. Create your first product and domain model. Create your first workflow and input form Note This workshop will guide the user through the basic principles of the orchestrator. For in depth questions please contact the maintainers","title":"Workshop overview"},{"location":"getting-started/workshop/step1/","text":"Step 1 - Project Setup Create a new repository and virtualenvironment to experiment with the orchestrator-core. Follow the steps below. Step 1 a $ mkdir hello-world-orchestrator $ cd hello-world-orchestrator $ git init $ git commit -am \"Initial commit\" $ mkvirtualenv -p python3.9 hello-world-orchestrator $ workon hello-world-orchestrator Step 1 b Follow the instructions laid out here","title":"Step 1 - Installation"},{"location":"getting-started/workshop/step1/#step-1-project-setup","text":"Create a new repository and virtualenvironment to experiment with the orchestrator-core. Follow the steps below.","title":"Step 1 - Project Setup"},{"location":"getting-started/workshop/step1/#step-1-a","text":"$ mkdir hello-world-orchestrator $ cd hello-world-orchestrator $ git init $ git commit -am \"Initial commit\" $ mkvirtualenv -p python3.9 hello-world-orchestrator $ workon hello-world-orchestrator","title":"Step 1 a"},{"location":"getting-started/workshop/step1/#step-1-b","text":"Follow the instructions laid out here","title":"Step 1 b"},{"location":"getting-started/workshop/step2/","text":"Step 2 - Running the orchestrator-core-gui The GUI application is a ReactJS application that can be run in front of the application. It will consume the API and enable the user to interact with the products, subscriptions and processes that are built and run in the orchestrator. The GUI is uses Elastic-UI as framework for standard components and Uniforms to parse JSON-Schema produced by the forms endpoints in the core and render the correct components and widgets. Clone the client repository $ git clone https://github.com/workfloworchestrator/orchestrator-core-gui.git Install the node modules and setup the environment The orchestrator client gui has a number of prerequisites: Node 14.15.0 yarn 1.22.11 $ yarn install $ cp .env.local.example .env.local $ source .env.local $ cd src $ ln -s custom-example custom $ yarn start Info The custom-example directory contains some SURF specific modules that can be used as an example. It must be linked to let the app startup","title":"Step 2 - App start up"},{"location":"getting-started/workshop/step2/#step-2-running-the-orchestrator-core-gui","text":"The GUI application is a ReactJS application that can be run in front of the application. It will consume the API and enable the user to interact with the products, subscriptions and processes that are built and run in the orchestrator. The GUI is uses Elastic-UI as framework for standard components and Uniforms to parse JSON-Schema produced by the forms endpoints in the core and render the correct components and widgets.","title":"Step 2 - Running the orchestrator-core-gui"},{"location":"getting-started/workshop/step2/#clone-the-client-repository","text":"$ git clone https://github.com/workfloworchestrator/orchestrator-core-gui.git","title":"Clone the client repository"},{"location":"getting-started/workshop/step2/#install-the-node-modules-and-setup-the-environment","text":"The orchestrator client gui has a number of prerequisites: Node 14.15.0 yarn 1.22.11 $ yarn install $ cp .env.local.example .env.local $ source .env.local $ cd src $ ln -s custom-example custom $ yarn start Info The custom-example directory contains some SURF specific modules that can be used as an example. It must be linked to let the app startup","title":"Install the node modules and setup the environment"},{"location":"getting-started/workshop/step3/","text":"Step 3 - Create a product in the database. The Core of the orchestrator revolves around the lifecycle management of a product. Workflows are written to transition subscriptions to a product from one status to another. Exercise - Create a product and workflow migration Create a migration with the following end result. Make a product named: Username registration . Make sure it has one product block One resource type called user_name To view the result go to http://localhost:3000/products A workflow called create_username related to the product in the database. Answer","title":"Step 3 - Create a product"},{"location":"getting-started/workshop/step3/#step-3-create-a-product-in-the-database","text":"The Core of the orchestrator revolves around the lifecycle management of a product. Workflows are written to transition subscriptions to a product from one status to another.","title":"Step 3 - Create a product in the database."},{"location":"getting-started/workshop/step3/#exercise-create-a-product-and-workflow-migration","text":"Create a migration with the following end result. Make a product named: Username registration . Make sure it has one product block One resource type called user_name To view the result go to http://localhost:3000/products A workflow called create_username related to the product in the database. Answer","title":"Exercise - Create a product and workflow migration"},{"location":"getting-started/workshop/step4/","text":"Step 4 - Create a domain mnodel To manipulate a subscription and to make use of the Typing of Pydantic in the workflows we define so-called Domain-Models. This construct enables the user to use the dot notation to interact with a subscription like it is a class. Read the Domain Models section to understand how the concept works. Exercise - Create a domain model The domain model is correctly implemented when it achieves the following goals: It must implement the life-cycles: Inintial and Active It must be possible to create an Subscription in the database through the domain model. Make use of .save() , .from_product() , from_lifecycle() and from_subscription() methods to manipulate the subscription. Tip Below you can find some hints towards the answers Take a look at the tests conftest.py to see how a domain model can be declared The Product migration must be setup corretly The Domain model needs to be registered in the product block model registry. You must create an is_base model.","title":"Step 4 - Define a domain model"},{"location":"getting-started/workshop/step4/#step-4-create-a-domain-mnodel","text":"To manipulate a subscription and to make use of the Typing of Pydantic in the workflows we define so-called Domain-Models. This construct enables the user to use the dot notation to interact with a subscription like it is a class. Read the Domain Models section to understand how the concept works.","title":"Step 4 - Create a domain mnodel"},{"location":"getting-started/workshop/step4/#exercise-create-a-domain-model","text":"The domain model is correctly implemented when it achieves the following goals: It must implement the life-cycles: Inintial and Active It must be possible to create an Subscription in the database through the domain model. Make use of .save() , .from_product() , from_lifecycle() and from_subscription() methods to manipulate the subscription. Tip Below you can find some hints towards the answers Take a look at the tests conftest.py to see how a domain model can be declared The Product migration must be setup corretly The Domain model needs to be registered in the product block model registry. You must create an is_base model.","title":"Exercise -  Create a domain model"},{"location":"getting-started/workshop/step5/","text":"Create a workflow The last step is to create a workflow. The way a workflow works is intricate and can be read about here . Safe to say is that in principe a workflow will execute a number of steps functions in order and pass state from one step to another through the database. The best workflow steps execute atomic functions that may fail and can be safely retried without human intervention. Exercise - create a workflow and input form Please do the following: Create a workflow file and register it in the workflow engine Declare an input form Fill out the subscription model and trasition it to the active state. Investigate how the client parses the form input to generate a form. Hint You need to create a LazyWorkflowInstance An input form generates a Form class. Generating multiple Forms in sequence creates a wizard like flow. Take have a look at the form schema and how it interacts with Uniforms","title":"Step 5 - Create a workflow"},{"location":"getting-started/workshop/step5/#create-a-workflow","text":"The last step is to create a workflow. The way a workflow works is intricate and can be read about here . Safe to say is that in principe a workflow will execute a number of steps functions in order and pass state from one step to another through the database. The best workflow steps execute atomic functions that may fail and can be safely retried without human intervention.","title":"Create a workflow"},{"location":"getting-started/workshop/step5/#exercise-create-a-workflow-and-input-form","text":"Please do the following: Create a workflow file and register it in the workflow engine Declare an input form Fill out the subscription model and trasition it to the active state. Investigate how the client parses the form input to generate a form. Hint You need to create a LazyWorkflowInstance An input form generates a Form class. Generating multiple Forms in sequence creates a wizard like flow. Take have a look at the form schema and how it interacts with Uniforms","title":"Exercise - create a workflow and input form"}]}